\begin{comment} \subsection{Infinite activity \levy jumps}
We now turn to the case of a price process specified in full generality by \eqref{eq:generalsemimartingale}, that is the price process is a sum of a continuous and a discontinuous process with possibly  infinite activity. The infinite activity assumption is equivalent to  the statement that $\nu$ assigns  infinite measure to the complement of the singleton containing zero.    The following is the consistency Proposition in this more general framework:
\end{comment}
We now prove consistency for the estimator when the price process admits both large and small jumps. That is 
\begin{align}
  X_t = X_0 + X^c_t + J^l_t + J^s_t. \notag
  \label{}
\end{align}
where $J^l_t := (xI_{\{\vert x \vert > 1\}}) \ast \mu_t$ and  $J^s := (xI_{\{\vert x \vert \le 1\}}) \ast (\mu - \nu)_t$.
First, we make some obvious statements:
\begin{lem}\label{lem:est}
  Let $X$ be an \ito semimartingale meetig the requirements of Assumption \ref{as:vol} and \ref{as:nu}. Let $\{T_m, F^m\}$ be a localizing sequence for $(b, \sigma, F)$. Denote $(X^c_m)_t := X^c_{t \wedge T_m}$,  $(J^l_m)_t := J^l_{t \wedge T_m}$, and $(J^s_m)_t := J^s_{t \wedge T_m}$. Then,
  \begin{enumerate}
    \item $\e((\dxc_m)^p) = O(\Delta_n^{p/2}), \qquad p \in \{2, 4\}$,
    \item $\e((\djt_m)^2) = O(\Delta_n)$,
    \item $\e(\vert \djl_m \vert ) = O(\Delta_n)$.
  \end{enumerate}
\end{lem}
\begin{proof}
That $\e((\dxc_m)^p) = O(\Delta_n^{p/2})$  for $p = 2$ and 4  holds has already been demonstrated in Proposition \ref{pro:finite}. Now, since $J^s$ is a local martingale, we have by  the BDG inequality that,   for $t \in (t_i, t_{i + 1}]$, 
\begin{align}
\e( ( J^s_{t\wedge T_m} - J^s_{t_{i}\wedge T_m})^2) &= \e(  [J^s_{t\wedge T_m} - J^s_{t_{i}\wedge T_m}]) \notag \\
& = \e(\int_{t_i \wedge T_m}^{t\wedge T_m}\int_{\{ \vert x \vert \le 1\}} x^2 F_t(dx) dt)\notag \\
& \le \e(\int_{t_i\wedge T_m}^{t\wedge T_m}\int_\real (x^2 \wedge \vert x \vert ) F_t(dx) dt)\notag \\
& \le  \int_{t_i\wedge T_m}^{t\wedge T_m}\int_\real (x^2 \wedge \vert x \vert) F^m(dx) dt\notag\\
%& \le  (t - t_i)\int_\real x^2 F^m(dx) \notag\\
& =  O(\Delta_n)\notag.
\end{align}
Similarly, 
\begin{align}
\e( \vert J^l_{t\wedge T_m} - J^l_{t_{i}\wedge T_m} \vert) &\le \e( (\vert x\vert I_{\{\vert x \vert > 1\}}) \ast \mu((t_i\wedge T_m, t_{i+1}\wedge T_m] ) \notag\\
& = \e(\int_{t_i\wedge T_m}^{t\wedge T_m}\int_{\{ \vert x \vert > 1\}} \vert x\vert F_t(dx) dt)\notag \\
& \le  \int_{t_i\wedge T_m}^{t\wedge T_m}\int_\real (x^2 \vee \vert x \vert) F^m(dx) dt\notag\\
& =  O(\Delta_n)\notag.
  \label{}
\end{align}
\end{proof}
\begin{comment}
First, we state some obvious results.
\begin{lem}
 Let the price process  $X$ be specified as in  \eqref{eq:semimartingale}. Then,
 \begin{enumerate}
   \item $(x^2 \wedge 1) \ast \mu$ is locally integrable.
   \item $(\vert x \vert I_{\{\vert x \vert > 1\}}) \ast \mu$ is locally integrable.
 \end{enumerate}
\end{lem}
The first statement follows because $(x^2 \wedge 1) \ast \mu_t$ is dominated by $ (x^2I_{\{\vert x \vert \le 1\}}) \ast \mu_t$ and $ (I_{\{\vert x \vert > 1\}}) \ast \mu_t$, which  are increasing processes with bounded jumps and, therefore, locally integrable.    
\end{comment}
We now give the main result of the paper.
\begin{prop} \label{pro:infinity}
  Let the price process  $X$ be specified as in  \eqref{eq:semimartingale}. We assume that the requirements of Assumption \ref{as:vol} and \ref{as:nu} are met. Let $\{g, \tg\}$ be pair of dual Gabor generators satisfying the conditions of Lemma \eqref{le:gabor} such that $g$ is Lipschitz continuous on the unit interval.
  Suppose the sequences $u_n \downarrow 0$ and $H_n \uparrow \infty$ satisfy 
  \begin{align}
    u_n^{-1/2}(H^n)^2\Delta_n^{1/2} = o(1).\notag
    \label{}
  \end{align} 
  \begin{comment}and   that $\nu$ satisfies 
   \begin{align}
    (x^2 \wedge u_n^{1/2}) \ast \nu_1 = o(H_n^{-2}).
    \label{eq:smallo}
  \end{align}
  \end{comment}
  Then  \jvn, defined in \eqref{eq:jumpvolestimator}, converges in \Ltwo in probability to \sv.
\end{prop}
\begin{proof}
  \begin{comment}  We wish to show that the random variable
  $\int_0^1 (\jvn - \sigma^2(t))^2\D t$ tends to zero in probability. The regularity conditions on $X$ and $\sigma^2$ imply that  $\sup_{t \in [0,1]} (\jvn - \sigma^2(t))^2$ is a random variable and that the previous claim would follow as soon as $\sup_{t \in [0,1]} (\jvn - \sigma^2(t))^2$ is shown  to converge to  zero in probability.\end{comment}
  Consider the following decomposition of the process $X$:
  \begin{align}
    &X = X^f + J^s\label{eq:xj},\\
    &X^f = X^c + J^l\label{eq:xjc},
  \end{align}
  where 
    $X^c = \int^t_0 b_s \D s + \int^t_0 \sigma_s \D W_s$, 
    $J^l = (xI_{\vert x \vert > 1}) \ast \mu,$
    and $J^s = (xI_{\vert x \vert \le  1} )\ast (\mu - \nu)$. By localization, it is enough to assume $\sigma^4$, $b^4$, and $x^2 \ast \mu_t$  are integrable. 
    Let $t$ be a point in the unit interval, then 
    \begin{align}
      \jvn -  \sigma^2_t &= \sumt (\ceen{X} - \cee) \ghk(t) - \sumnt \cee \ghk(t),
      \label{eq:open}
    \end{align}
    with $\ceen{X}$ and $\cee$ defined by \eqref{eq:jumpvolestimator} and \eqref{eq:chk}, respectively. The last term tends to zero, almost surely, in \Ltwo as $n \to \infty$ because Gabor frames converge unconditionally. 
    
     To obtain a bound on the first item on the right of \eqref{eq:open}, we may use \eqref{eq:xj} to write
    \begin{align}
      \sumt &(\ceen{X} - \cee)\ghk(t)   = \sumt (w_{h,k} + x_{h,k} + y_{h,k} + z_{h,k}) \ghk(t),\label{eq:summands} 
    \end{align}
    where 
    \begin{align}
      &w_{h,k} :=  \sumin \btghki  (\dxf)^2 \indxff - \int^{1}_{0} \sigma^2(s) \btghks \D s \notag\\
      &x_{h,k} :=  \sumin \btghki(\dxf)^2 (\indx - \indxff) \notag\\
      &y_{h,k}  := 2 \sumin \btghki\dxf \djt \indx \notag \\
      &z_{h,k} := \sumin \btghki(\djt)^2\indx.
      \label{}
    \end{align}
    By Lemma \eqref{lem:finite}, if $\delta > 0$ then %\begin{align}  
      $\p(\sup_{t \in [0,1]}\vert \sumt w_{h,k} \ghk(t) \vert > \delta) \to 0$ %\label{eq:w} \end{align} 
    as $n$ tends to infinity.  It remains to show that the last three terms on the right of \eqref{eq:summands} converge to zero in probability. Starting with the second summand, denote $A_i := \{(\dx)^2 \le u_n\}$,  $B_i   := \{(\dxf)^2 \le 4 u_n\}$ and note that $I_{A_i} - I_{B_i} = I_{A_i \cap B_i^c} - I_{A^c_i\cap B_i}$. By the reverse triangle inequality,   $A_i \cap B_i^c \subset \{\vert \djt \vert > u_n^{1/2}\}$. Hence, 
    \begin{align}
      (\dxf)^2 I_{A_i \cap B_i^c} &\le (\dxf)^2 I_{\{(\djt)^2 > u_n\}}\\
       & \le 2 (\dxc)^2 I_{\{(\djt)^2 > u_n\}}
       + 2 (\djl)^2 I_{\{(\djt)^2 > u_n\}}\notag\\
       & =: v_i + w_i. 
      \label{eq:longineq}
    \end{align}
    \begin{comment}
    where \begin{align} &v_n :=  2c H_n \Lambda n^{-1} \log(n) \sumin I_{\{(\djt)^2 > u_n\}} \notag \\ & w_n: = c H_n \sumin  (\djl)^2 I_{\{(\djt)^2 > u_n\}}\notag \end{align}  where $c$ is a sufficiently large constant, and $\Lambda$ is a finite-valued random variable satisfying  $\Lambda \ge  \sup_{t \in \domain} \vert b(t)\vert  + C $, where $C^{1/2}$ is the finite-valued random variable from Lemma \ref{lem:mylevy}.  Let  $\delta > 0$ be given, put  $x_n(t)  :=  \sumt\left(\sumin  \btghki(\dxf)^2 I_{A_i \cap B_i^c})\right)\ghk(t)$  and note that 
    \begin{align}
      \p &\left(  \sup_{t \in \domain}\vert x_n (t) \vert  > \delta\right) \le \p(v_n > \delta/2) + \p(w_n > \delta/2) \notag. 
      \label{}
    \end{align}
  Now let  $\varepsilon > 0$ be given and note that because  $\Lambda$ is almost surely finite,   there is a sufficiently large $K > 0$ such that $\p(\Lambda > K) \le \varepsilon/2$. Hence, 
\end{comment}
By Lemma \ref{lem:est},
\begin{align} 
  \e(v_i) & = 2 \e( (\dxc)^4)^{1/2} \p( (\djt)^2 > u_n)^{1/2} \notag \\ 
  & = 2 u_n^{-1/2} \e( (\dxc)^4)^{1/2} \e( (\djt)^2)^{1/2} \notag \\ 
  & \le c u_n^{-1/2}\Delta_n^{3/2} \label{eq:vi}.
\end{align}
Hence,  by Markov's inequality and the boundedness of $\ghk$ \begin{align} \sup_{t \in \domain}\sumnt \sumin \btghki v_i \ghk(t) = O_P(u_n^{-1/2}H^n \Delta_n^{1/2}).\end{align} 
Now denote $\Omega_k := \{ I_{\{\vert x \vert > 1\}} \ast \mu(\real \times [0,1]) \le k\}$ for all $k \in \nats$. Then $\p(\Omega_k) \to 1$ as $k \to \infty$.
By Assumption \ref{as:nu}, the jumps of $X$ up to time $T_m$ are square integrable so that for each $k$
\begin{align}
  \e(w_i) &= 2 \e((\djl)^2 I_{\{(\djt)^2 > u_n\}})\notag\\
  &\le c k  \p((\djt)^2 > u_n)^{1/2}\notag\\
  &\le c k  u^{-1/2}_n \Delta_n^{1/2}. 
  \label{}
\end{align}
Hence,  by Markov's inequality and the boundedness of $\ghk$, given $\eta > 0$, \begin{align} \p( \sup_{t \in \domain}\vert \sumnt \sumin \btghki w_i \ghk(t)\vert > \eta) \le \p(\Omega_k^c) + ckH^n (u^{-1}_n\Delta_n)^{1/2}, \notag \end{align}
which tends to zero simulatneously in $k$ and $n$.
  \begin{comment}
\p(v_n > \delta /2) & \le 2cKH_n\delta^{-1}E(n^{-1} \log(n) \sumin I_{\{(\djt)^2 > u_n\}}) + \p(\Lambda > K) \notag  \\ & = 2cK H_n\delta^{-1}\log(n) \p( (\Delta_{1/n}J^s)^2 > u_n)  + \varepsilon/2 \notag \\ &\le  2cK H_n\delta^{-1}\log(n) E((\Delta_{1/n} J^s)^2))u_n^{-1}   + \varepsilon/2 \notag \\ &\le 2cKH_n\delta^{-1} \log(n) n^{-1}\kappa u_n^{-1} +  \varepsilon/2\label{eq:asabove} \end{align} where $\kappa := E((\Delta_1 J^s)^2)) < \infty$.  Obviously there is a large enough $n$ such that the first expression above is less than or equal to $\varepsilon/2$.
\end{comment}
\begin{comment} Moreover, because $\delta >  0$,  \begin{align} \p(w_n > \delta/2) & \le \p\left(\cup_i\{I_{\{\vert x \vert > 1\}}\ast \mu( (t_i, t_{i + 1}] \times \real) > 0   , (\djt)^2 > u_n\}\right) \notag \\ & \le n \p(\mu( [0, 1/n] \times \{\vert x \vert > 1\}) > 0 ) E( (\Delta_1 J^s)^2) u_n^{-1} \notag \\ & \le c n^{-1} \kappa u_n^{-1}\notag,\end{align} which clearly tends to zero in $n$. 
\end{comment}

Now, define
\begin{align}
&\Omega_n^1 := \{\omega : \vert \dxf(\omega) \vert > 2u^{1/2}_n, \forall  i < n\},\notag \\ 
&\Omega_n^2 := \{\omega : \mu(\omega,  (t_i, t_{i+1}] \times \{\vert x \vert > 1\} ) \le 1, \forall i <n  \},\notag 
\end{align}
$\forall n \in \nats$. These sets are clearly measurable. Denote $\Omega_n   := \Omega_n^1 \cap \Omega_n^2 $. Since there can be at most a finite number of jumps  larger than 1,  in absolute value, per outcome on \domain and  $u_n \downarrow 0$ while $X^c$ is uniformly continuous on \domain, it follows that $ \p(\Omega_n) \to 1$ as $n \to \infty$ (See \eqref{eq:well1}). Now note that 
\begin{align}
  \notag
  A_i^c \cap B_i \cap \Omega_n & \subset  \{ (\dxc + \djt)^2 > u_n \} \notag\\
  &\subset \{(\dxc)^2 > u_n/4\} \cup \{(\djt)^2 > u_n/4\}\notag .
  \label{}
\end{align}
Hence, by successive applications of \holder and Markov inequaities followed by Lemma \ref{lem:est},   
\begin{align}
  \notag
 \e(&(\dxf)^2 I_{A_i^c \cap B_i \cap \Omega_n} ) = \e((\dxc)^2 I_{A_i^c \cap B_i \cap \Omega_n} )\notag \\
 &\le \e((\dxc)^2 I_{\{(\dxc)^2 > u_n/4\}}) + \e((\dxc)^2 I_{\{(\djt)^2 > u_n/4\}}) \label{} \notag\\
 & \le c \Delta_n^{3/2} u_n^{-1/2}.\notag
\end{align}
Let $\eta$ be a given positive number; put $y_i :=  (\dxf)^2 I_{A_i^c \cap B_i}$. Then it is clear that
\begin{align}
  \p(\sup_{t \in \domain} \vert \sumt\sumin  \btghki y_i \ghk(t)\vert  > \eta) \le  \p(\Omega_n^c)  + c u^{-1/2}_nH^n\Delta_n^{1/2}, \notag
  \label{}
\end{align}
which tends to zero in $n$.  This completes the proof that \begin{align}\label{eq:x} \p(\sup_{t \in [0,1]}\vert \sumt x_{h,k} \ghk(t) \vert > \eta) \to 0. \end{align}

Now we obtain a bound for the third summand in  \eqref{eq:summands}. First, denote $C_i := \{( \djt )^2 \le 4 u_n\}$, $p_{h,k} : = 2 \sumin \btghki\dxf \djt I_{A_i \cap C_i}$, and $q_{h,k} := 2 \sumin \btghki\dxf \djt I_{A_i \cap C_i^c}$. Clearly, $\sumnt y_{h,k} \ghk(t)  = \sumnt (p_{h,k} + q_{h,k}) \ghk(t)$. By the reverse triangle inequality,
\begin{align}
  A_i \cap C_i^c &\subset \{ u_n^{1/2} < \vert \dxf \vert  \}\notag\\
  & \subset \{ u_n^{1/2}/2 < \vert \dxc \vert  \} \cup  \{ u_n^{1/2}/2 < \vert \djl \vert  \}\notag\\
  &=: G^1_i \cup G^2_i\notag.
  \label{}
\end{align}
So that 
\begin{align}
  \dxf \djt I_{A_i \cap C_i^c} &\le \dxf \djt  (I_{G^1_i} +  I_{G^2_i}) \notag\\
  & \le \dxc \djt(I_{G^1_i} +  I_{G^2_i}) + \djl \djt(I_{G^1_i} +  I_{G^2_i}) \notag \\
  & =: \gamma_i^1 + \gamma_i^2 + \gamma_i^3 + \gamma^4_i.\notag 
\end{align}
Now,
\begin{align}
  \e(\gamma_i^1) &\le  \e( (\dxc  I_{G^1_i})^2)^{1/2} \e( (\djt)^2)^{1/2} \notag\\
  &\le  \e( (\dxc)^4)^{1/4}  E(I_{G^1_i})^{1/4} \e( (\djt)^2)^{1/2} \notag\\
  & \le c \Delta_n^{1/2} (u^{-1/2}_n \Delta_n^{1/2}) \Delta_n^{1/2} \notag \\
  & \le c u^{-1/2}_n \Delta_n^{3/2}.
  \label{}
\end{align}
Hence, given positive $\eta$, 
\begin{align} 
  \p( \sup_{t \in \domain}\vert \sumnt \sumin \btghki \gamma^1_i \ghk(t)\vert > \eta) \le cH^n (u^{-1}_n\Delta_n)^{1/2}. \notag \end{align}
Similarly, but without the benefit of the existence of a second moment for \djl, we have 
\begin{align}
  \e(\gamma_i^2) & =  \e(\dxc \djt I_{G^2_i}) \notag\\
  & \le \e((\dxc)^2 I_{G^2_i})^{1/2} \e((\djt)^2)^{1/2}\notag \\
  &\le \e((\dxc)^4)^{1/4} \p(\djl > u_n^{1/2}/2)^{1/4} \e((\djt)^2)^{1/2}\notag\\
  & \le  c u^{-1/8}_n \Delta_n^{5/4}\notag.
  \label{}
\end{align}
So that given positive $\eta$,
\begin{align} 
  \p( \sup_{t \in \domain}\vert \sumnt \sumin \btghki \gamma^2_i \ghk(t)\vert > \eta) \le cH^n (u^{-1/2}_n\Delta_n)^{1/4}. \notag \end{align}
Now consider the events, $\Omega_q := \{\omega : \mu(\omega, \domain  \times \{\vert x \vert > 1\} ) \le q \}$, for     $q \in \nats$. It is easily seen that $\p(\Omega_q) \to 1$ as $q \to \infty$. Set $\Omega(n, q) := \Omega_n \cap \Omega_q$. Now note that   $\e(\gamma^3_i I_{\Omega(n,q)}) \le q \e(\djt I_{G^1_i}) \le c q \Delta_n^{3/2} u_n^{-1/2}$. So that given positive $\eta$,
\begin{align} 
  \p( \sup_{t \in \domain}&\vert \sumnt \sumin \btghki \gamma^3_i \ghk(t)\vert > \eta) \notag \\ &\le \p(\Omega(n,q)^c) + cqH^n (u^{-1}_n\Delta_n)^{1/2}, \notag \end{align}
which can be made arbitrarily small by  choosing $n,q$ large enough and letting $n \to \infty$.  Similarly note that $\e(\gamma^4_i I_{\Omega(n,q)}) \le q \e(\djt I_{G^2_i}) \le c q \Delta_n u_n^{-1/4}$. So that 
\begin{align} 
  \p( \sup_{t \in \domain}\vert \sumnt \sumin \btghki \gamma^4_i \ghk(t)\vert > \eta) \le \p(\Omega(n,q)^c) + cqH^n u^{-1/4}_n\Delta_n, \notag \end{align}
which can be made as small as desired. This completes the demonstration  that 
\begin{align}
  \p(\sup_{t \in \domain} \vert \sumnt q_{h,k} \ghk(t) \vert > \eta) \to 0.\notag
  \label{}
\end{align}
\begin{comment}
Now, arguing as in Theorem 4.1 of \cite{Mancini2009}, note that on $ A_i \cap C_i^c$, it is the case that  $2u_n^{1/2} - \vert \dxf \vert < \vert \djt\vert - \vert \dxf\vert \le \vert \dx \vert \le u_n^{1/2}$, so that $u_n^{1/2} < \vert \dxf \vert < \vert \djl \vert + \vert \dxc \vert $. In turn, the last inequality implies that either $\vert \djl \vert > u^{1/2}_n/2$ or  $\vert \dxc \vert > u^{1/2}_n/2$. Now, for sufficiently large $n$, it is almost surely never the case that $\vert \dxc \vert > u^{1/2}_n/2$ for some $i$,  $0 \le  i  \le n -1$. Hence,  for positive $\delta$, \begin{align} \p(\vert&\sumt q_{h,k} \ghk(t) \vert > \delta/2) \notag \\ &\le \p(    \cup_i\{ \mu( (t_i, t_{i+1}] \times \{\vert x \vert > 1 \} ) > 0,  (\djt)^2 > u_n\}) \notag \\ & \le c n^{-1} \kappa u_n^{-1}.\end{align}
\end{comment}
Meanwhile, on $A_i \cap C_i$, it is easily seen that $\vert \djl \vert - \vert \dxc + \djt \vert < \vert \dx \vert \le u_n^{1/2}$, so that
\begin{align}
  \notag
  \dxf \djt I_{A_i \cap C_i} &\le \dxf \djt I_{\{\vert \djl \vert \le 4 u^{1/2}_n\}}\\
   &\le \dxc \djt I_{\{\vert \djl \vert \le 4 u^{1/2}_n\}} +  \djl \djt I_{\{\vert \djl \vert \le 4 u^{1/2}_n\}}\notag\\
   & =: \theta_i^1 + \theta_i^2\notag. 
  \label{}
\end{align}
Arguing as above, it is easily verified that $\e(\theta_i^1)  \le c \Delta_n^{5/4} u_n^{-1/8}$  so that 
\begin{align} 
  \p( \sup_{t \in \domain}\vert \sumnt \sumin \btghki \theta^1_i \ghk(t)\vert > \eta) \le cH^n (u^{-1/2}_n\Delta_n)^{1/4} \notag \end{align}
Similarly,  $\e(\theta_i^2 I_{\Omega(n,q)}) \le q c \Delta_n u^{-1/4}_n$ so that  
\begin{align} 
  \p( \sup_{t \in \domain}\vert \sumnt \sumin \btghki \theta^2_i &\ghk(t)\vert > \eta) \notag \\ &\le \p(\Omega(n,q)^c) + cH^n (u^{-1/2}_n\Delta_n)^{1/4} \notag \end{align}
Hence, 
\begin{align}
  \p(\sup_{t \in \domain} \vert \sumnt p_{h,k} \ghk(t) \vert > \eta) \to 0.\notag
  \label{}
\end{align}
This completes the demonstration  that 
\begin{align}
  \p(\sup_{t \in \domain} \vert \sumnt y_{h,k} \ghk(t) \vert > \eta) \to 0.\notag
  \label{}
\end{align}

$\vert \djl\vert \le u^{1/2}_n + \vert \dxc \vert + \vert \djt\vert \le 4u^{1/2}_n$. So that  On the other hand, $ \vert \djl \vert < u_n^{1/2} + \Lambda n^{-1/2} \log^{1/2}(n) + 2 u_n^{1/2} = O(u^{1/2}_n)$. Let $r_{h,k} :=  2 \sumin \btghki\dxc \djt I_{A_i \cap C_i}$ and $s_{h,k} := 2 c u_n^{1/2}\sumin \btghki \djt I_{A_i \cap C_i}$. Then 
\begin{align}
 \p(\vert&\sumt q_{h,k} \ghk(t) \vert > \delta/2)\notag \\&  \le\p(\vert\sumt r_{h,k} \ghk(t) \vert > \delta/4) + \p(\vert\sumt s_{h,k} \ghk(t) \vert > \delta/4).\notag
  \label{}
\end{align}
Now consider that $\sumt r_{h,k} \ghk(t) \le  c H_n \sumin \dxc \djt I_{A_i \cap C_i}$, which implies that  
\begin{align}
  \p(&\vert\sumt r_{h,k} \ghk(t) \vert > \delta/4) \le \p(c H_n \vert \sumin \dxc \djt I_{A_i \cap C_i} \vert  > \delta/4)\notag\\& \le \p\left( \left(\sumin (\dxc)^2\right)^{1/2} \left(\sumin ( \djt I_{A_i \cap C_i})^2\right)^{1/2} > \delta (4H_nc)^{-1}\right).\notag
  \label{}
\end{align}
It is a well known fact that  $\sumin (\dxc)^2 (t)$ converges to $\int_0^t\sigma^2(s)\D s$ in probability uniformly on the unit interval. Hence, there is a sufficiently large $N$ such that if $n > N$ then $ \p(\vert (\sumin (\dxc)^2)^{1/2}  - (\int_0^1\sigma^2(s) \D s)^{1/2}\vert > \delta ) \le  \varepsilon/4$, and because integrated volatility is almost surely finite, there is a sufficiently large $K$ satisfying  $K/2 > \delta$ such that $\p( \int_0^1\sigma^2(s) \D s > K/2) \le \varepsilon/4.$ Hence, we may write
\begin{align}
\p(&\vert\sumt r_{h,k} \ghk(t) \vert > \delta/4) \notag \\&\le \p\left(\sumin ( \djt I_{A_i \cap C_i})^2 > \delta^2 (4K H_nc)^{-2}\right) + \varepsilon/2\notag\\&\le  \p\left( (x^2I_{\{\vert x\vert \le 1 \wedge 2 u_n^{1/2}\}}\ast\mu)_1 > \delta^2 (4K H_nc)^{-2}\right) + \varepsilon/2\notag\\
&\le \delta^{-2} (4K H_nc)^{2}\e\left( (x^2I_{\{\vert x\vert \le 1 \wedge 2 u_n^{1/2}\}}\ast\mu)_1  \right) + \varepsilon/2\notag\\
&\le \delta^{-2} (4K H_nc)^{2} (x^2I_{\{\vert x\vert \le 1 \wedge 2 u_n^{1/2}\}}\ast\nu)_1   + \varepsilon/2\notag
  \label{}
\end{align}
which for sufficiently large $n$ is  less than $\varepsilon$ by \eqref{eq:smallo}.

Now it is easily seen that for sufficiently large $c$
\begin{align}
  \p(&\vert \sumt s_{h,k} \ghk(t) \vert > \delta/4) \le \p( \sumin  \djt I_{A_i \cap C_i} > (8 c u_n^{1/2})^{-1}\delta) \notag\\
  &\le (64 c^2 u_n)\delta^{-2} \e\left( (x^2I_{\{\vert x\vert \le 1 \wedge 2 u_n^{1/2}\}}\ast\mu)_1  \right)\notag \\
  & \le  (64 c^2 u_n)\delta^{-2} (x^2I_{\{\vert x\vert \le 1 \wedge 2 u_n^{1/2}\}}\ast\nu)_1
  \label{}
\end{align}
which, as above, is  less than $\varepsilon/4$ for sufficiently large $n$.
Hence, 
\begin{align}
  \notag
  \p(\sup_{t \in [0,1]}\vert \sumt y_{h,k} \ghk(t) \vert > \delta) \to 0.\label{eq:y}
\end{align}

Next,  write $z_{h,k} = a_{h,k} + b_{h,k}$ where $a_{h,k} :=  \sumin \btghki(\djt)^2I_{A_i \cap C_i}$ and  $b_{h,k} := \sumin \btghki(\djt)^2I_{A_i \cap C_i^c}$. Then 
\begin{align}
  \p(&\vert \sumt z_{h,k} \ghk(t) \vert   > \delta) \notag \\ &\le \p(\vert \sumt a_{h,k} \ghk(t) \vert > \delta/2) + \p(\vert \sumt b_{h,k} \ghk(t) \vert > \delta/2)\notag.
\end{align}
In the first instance,
\begin{align}
  \p(&\vert \sumt b_{h,k} \ghk(t) \vert > \delta/2) \notag \\ &\le
\p\left(\cup_i\{I_{\{\vert x \vert > 1\}}\ast \mu( (t_i, t_{i + 1}] \times \real) > 0   , (\djt)^2 > 4u_n\}\right) \notag \\
&\le n \p(I_{\{\vert x \vert > 1\}}\ast \mu( [0, 1/n] \times \real) > 0) \e((\djt)^2)(4u_n)^{-1}\notag \\
&\le cn^{-1}\kappa  u^{-1}_n.
\end{align}
which can be made as small as desired. Now consider
\begin{align}
  \p(&\vert \sumt a_{h,k} \ghk(t) \vert > \delta/2) \notag \\ &\le \p( \sumin (\djt)^2 I_{\{\vert \djt \vert \le 2u_n^{1/2} \}} > \delta (2 c H_n)^{-1} )\notag\\
  &\le\delta^{-1} (2 c H_n)\e\left( x^2I_{\{\vert x\vert \le 1 \wedge 2 u_n^{1/2}\}}\ast\mu_1  \right)\notag \\
  &\le \delta^{-1} (2 c H_n) (x^2I_{\{\vert x\vert \le 1 \wedge 2 u_n^{1/2}\}}\ast\nu)_1
\notag
  \label{}
\end{align}
which can be made arbitrarily small.
Hence, 
\begin{align}
  \p(\sup_{t \in [0,1]}\vert \sumt z_{h,k} \ghk(t) \vert > \delta) \to 0.\label{eq:z}
\end{align}
The result follows from \eqref{eq:w},\eqref{eq:x},\eqref{eq:y}, and \eqref{eq:z}.
\end{proof}

